{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import enum\n",
    "\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from scipy.sparse import coo_matrix, dok_matrix, lil_matrix, csr_matrix, bsr_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input path\n",
    "Set this to the location of input .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_d = Path('../input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To line-profile a function:\n",
    "\n",
    "```\n",
    "conda install -c anaconda line_profiler\n",
    "```\n",
    "\n",
    "Then run:\n",
    "\n",
    "```\n",
    "%lprun -f f1 f2(...)\n",
    "```\n",
    "\n",
    "Both functions `f1` and `f2` can be the same or different ie. your code starts at `f2` but you are only interested in profiling `f1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: line_profiler in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.3.1)\n",
      "Requirement already satisfied: IPython<7.17.0,>=0.13; python_version <= \"3.6\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from line_profiler) (7.16.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (4.8.0)\n",
      "Requirement already satisfied: decorator in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (5.0.9)\n",
      "Requirement already satisfied: pygments in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (50.3.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.7.5)\n",
      "Requirement already satisfied: backcall in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from jedi>=0.10->IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.7.1)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from traitlets>=4.2->IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from traitlets>=4.2->IPython<7.17.0,>=0.13; python_version <= \"3.6\"->line_profiler) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'line_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-df8a33df4eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'line_profiler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-57>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38_pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'line_profiler'"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _H:\n",
    "    '''Hyperparams'''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__ = kwargs\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = _H(\n",
    "    version = '210101b',\n",
    "    max_users = 450000,\n",
    "    max_questions = 13523,\n",
    "    valid_pct = 0.025, # ~2.5M rows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(df, cols):\n",
    "    cats_d = {}\n",
    "    for col in cols:\n",
    "        if df[col].dtype.name == 'category':\n",
    "            print(f'{col} already categorized')\n",
    "        else:\n",
    "            df[col] = pd.Categorical(df[col])\n",
    "        cats_d[col] = df[col].cat.categories.values\n",
    "    return cats_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_stds(df, cols):\n",
    "    return { col: df[col].mean() for col in cols }, { col: df[col].std() for col in cols }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': array([    0,     1,     2, ..., 13520, 13521, 13522]),\n",
       " 'bundle_id': array([    0,     1,     2, ..., 13520, 13521, 13522]),\n",
       " 'correct_answer': array([0, 1, 2, 3]),\n",
       " 'part': array([1, 2, 3, 4, 5, 6, 7])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_dtypes = {\n",
    "    'question_id': 'int16',\n",
    "    'bundle_id': 'int16',\n",
    "    'correct_answer': 'int8',\n",
    "    'part': 'int8',\n",
    "    'tags': 'object',\n",
    "}\n",
    "\n",
    "questions_df = pd.read_csv(\n",
    "    in_d / 'questions.csv',\n",
    "    usecols=question_dtypes.keys(),\n",
    "    dtype=question_dtypes,\n",
    ")\n",
    "\n",
    "qcats = categorize(questions_df, ['question_id', 'bundle_id', 'correct_answer', 'part'])\n",
    "qcats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split tags\n",
    "Tag `n` is renumbered to `n+1` so that 0 means \"no tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df[[f'tag_{_}' for _ in range(6)]] = (questions_df.tags.str.split(expand=True).fillna('-1').astype('int16') + 1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13523 entries, 0 to 13522\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   question_id     13523 non-null  category\n",
      " 1   bundle_id       13523 non-null  category\n",
      " 2   correct_answer  13523 non-null  category\n",
      " 3   part            13523 non-null  category\n",
      " 4   tags            13522 non-null  object  \n",
      " 5   tag_0           13523 non-null  uint8   \n",
      " 6   tag_1           13523 non-null  uint8   \n",
      " 7   tag_2           13523 non-null  uint8   \n",
      " 8   tag_3           13523 non-null  uint8   \n",
      " 9   tag_4           13523 non-null  uint8   \n",
      " 10  tag_5           13523 non-null  uint8   \n",
      "dtypes: category(4), object(1), uint8(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "questions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>52</td>\n",
       "      <td>132</td>\n",
       "      <td>163</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>132</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 101 162 92</td>\n",
       "      <td>132</td>\n",
       "      <td>102</td>\n",
       "      <td>163</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 149 162 29</td>\n",
       "      <td>132</td>\n",
       "      <td>150</td>\n",
       "      <td>163</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>131 5 162 38</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>13518</td>\n",
       "      <td>13518</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>13519</td>\n",
       "      <td>13519</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>13520</td>\n",
       "      <td>13520</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>13521</td>\n",
       "      <td>13521</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>13522</td>\n",
       "      <td>13522</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13523 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id bundle_id correct_answer part            tags  tag_0  tag_1  \\\n",
       "0               0         0              0    1   51 131 162 38     52    132   \n",
       "1               1         1              1    1       131 36 81    132     37   \n",
       "2               2         2              0    1  131 101 162 92    132    102   \n",
       "3               3         3              0    1  131 149 162 29    132    150   \n",
       "4               4         4              3    1    131 5 162 38    132      6   \n",
       "...           ...       ...            ...  ...             ...    ...    ...   \n",
       "13518       13518     13518              3    5              14     15      0   \n",
       "13519       13519     13519              3    5               8      9      0   \n",
       "13520       13520     13520              2    5              73     74      0   \n",
       "13521       13521     13521              0    5             125    126      0   \n",
       "13522       13522     13522              3    5              55     56      0   \n",
       "\n",
       "       tag_2  tag_3  tag_4  tag_5  \n",
       "0        163     39      0      0  \n",
       "1         82      0      0      0  \n",
       "2        163     93      0      0  \n",
       "3        163     30      0      0  \n",
       "4        163     39      0      0  \n",
       "...      ...    ...    ...    ...  \n",
       "13518      0      0      0      0  \n",
       "13519      0      0      0      0  \n",
       "13520      0      0      0      0  \n",
       "13521      0      0      0      0  \n",
       "13522      0      0      0      0  \n",
       "\n",
       "[13523 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = questions_df.drop('tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert np.all(questions_df.isna() == False) # no nans\n",
    "assert np.all(questions_df.values < 2**16) # all fit in int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcols = questions_df.columns.to_list()\n",
    "QCols = enum.IntEnum('QCols', qcols, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcodes_d = {}\n",
    "for col, cats in qcats.items():\n",
    "    # code=0 is reserved for <NA>, NaN and the likes\n",
    "    qcodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_d = {}\n",
    "for row in questions_df.to_numpy():\n",
    "    question_id_code = qcodes_d['question_id'][row[QCols.question_id]]\n",
    "    qc_d[question_id_code] = np.array([\n",
    "        question_id_code,\n",
    "        qcodes_d['bundle_id'][row[QCols.bundle_id]],\n",
    "        qcodes_d['correct_answer'][row[QCols.correct_answer]],\n",
    "        qcodes_d['part'][row[QCols.part]],\n",
    "        row[QCols.tag_0],\n",
    "        row[QCols.tag_1],\n",
    "        row[QCols.tag_2],\n",
    "        row[QCols.tag_3],\n",
    "        row[QCols.tag_4],\n",
    "        row[QCols.tag_5],\n",
    "    ], dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_dtypes = {\n",
    "    'lecture_id': 'int64',\n",
    "    'tag': 'uint8',\n",
    "    'part': 'int8',\n",
    "    'type_of': 'object'\n",
    "}\n",
    "\n",
    "lectures_df = pd.read_csv(\n",
    "    in_d / 'lectures.csv',\n",
    "    usecols=lecture_dtypes.keys(),\n",
    "    dtype=lecture_dtypes,\n",
    ")\n",
    "\n",
    "lcats = categorize(lectures_df, ['lecture_id', 'part', 'type_of'])\n",
    "#lectures_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(lcats['part'] == qcats['part']) # all parts show up on both dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Tag `n` is renumbered to `n+1` here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures_df['tag_0'] = (lectures_df.tag.fillna('-1').astype('int16') + 1).astype('uint8')\n",
    "for i in range(1, 6):\n",
    "    lectures_df[f'tag_{i}']= pd.Series(0, index=lectures_df.index, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   lecture_id  418 non-null    category\n",
      " 1   tag         418 non-null    uint8   \n",
      " 2   part        418 non-null    category\n",
      " 3   type_of     418 non-null    category\n",
      " 4   tag_0       418 non-null    uint8   \n",
      " 5   tag_1       418 non-null    uint8   \n",
      " 6   tag_2       418 non-null    uint8   \n",
      " 7   tag_3       418 non-null    uint8   \n",
      " 8   tag_4       418 non-null    uint8   \n",
      " 9   tag_5       418 non-null    uint8   \n",
      "dtypes: category(3), uint8(7)\n",
      "memory usage: 24.6 KB\n"
     ]
    }
   ],
   "source": [
    "lectures_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>concept</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>32535</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>solving question</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>32570</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>solving question</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>32604</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>concept</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>32625</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>concept</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>32736</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>concept</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lecture_id  tag part           type_of  tag_0  tag_1  tag_2  tag_3  tag_4  \\\n",
       "0           89  159    5           concept    160      0      0      0      0   \n",
       "1          100   70    1           concept     71      0      0      0      0   \n",
       "2          185   45    6           concept     46      0      0      0      0   \n",
       "3          192   79    5  solving question     80      0      0      0      0   \n",
       "4          317  156    5  solving question    157      0      0      0      0   \n",
       "..         ...  ...  ...               ...    ...    ...    ...    ...    ...   \n",
       "413      32535    8    5  solving question      9      0      0      0      0   \n",
       "414      32570  113    3  solving question    114      0      0      0      0   \n",
       "415      32604   24    6           concept     25      0      0      0      0   \n",
       "416      32625  142    2           concept    143      0      0      0      0   \n",
       "417      32736   82    3           concept     83      0      0      0      0   \n",
       "\n",
       "     tag_5  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "413      0  \n",
       "414      0  \n",
       "415      0  \n",
       "416      0  \n",
       "417      0  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lectures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures_df = lectures_df.drop('tag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lectures_df.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcols = lectures_df.columns.to_list()\n",
    "LCols = enum.IntEnum('LCols', lcols, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcodes_d = {}\n",
    "for col, cats in lcats.items():\n",
    "    # code=0 is reserved for <NA>, NaN and the likes\n",
    "    lcodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert max([ max(col_codes.values()) for col_codes in lcodes_d.values() ]) < 2**15 # fit in int16?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_d = {}\n",
    "for row in lectures_df.to_numpy():\n",
    "    lecture_id_code = lcodes_d['lecture_id'][row[LCols.lecture_id]]\n",
    "    lc_d[lecture_id_code] = np.array([\n",
    "        lecture_id_code,\n",
    "        lcodes_d['part'][row[LCols.part]],\n",
    "        lcodes_d['type_of'][row[LCols.type_of]],\n",
    "        row[LCols.tag_0],\n",
    "        row[LCols.tag_1],\n",
    "        row[LCols.tag_2],\n",
    "        row[LCols.tag_3],\n",
    "        row[LCols.tag_4],\n",
    "        row[LCols.tag_5],\n",
    "    ], dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 7.52 s, total: 1min 51s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "interaction_dtypes = {\n",
    "    'row_id': 'int32',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32',\n",
    "    'content_id': 'int16',\n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'user_answer': 'int8',\n",
    "    'answered_correctly': 'int8',\n",
    "    'prior_question_elapsed_time': 'float32',\n",
    "    'prior_question_had_explanation': 'boolean'\n",
    "}\n",
    "\n",
    "i_df = pd.read_csv(\n",
    "    in_d / 'train.csv', \n",
    "    usecols=interaction_dtypes.keys(),\n",
    "    dtype=interaction_dtypes,\n",
    "    #nrows=10**6,\n",
    ")\n",
    "\n",
    "icats = categorize(i_df, ['task_container_id', 'user_answer', 'answered_correctly', 'prior_question_had_explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101230332 entries, 0 to 101230331\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Dtype   \n",
      "---  ------                          -----   \n",
      " 0   row_id                          int32   \n",
      " 1   timestamp                       int64   \n",
      " 2   user_id                         int32   \n",
      " 3   content_id                      int16   \n",
      " 4   content_type_id                 int8    \n",
      " 5   task_container_id               category\n",
      " 6   user_answer                     category\n",
      " 7   answered_correctly              category\n",
      " 8   prior_question_elapsed_time     float32 \n",
      " 9   prior_question_had_explanation  category\n",
      "dtypes: category(4), float32(1), int16(1), int32(2), int64(1), int8(1)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "i_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, True], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icats['prior_question_had_explanation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "icols = i_df.columns.to_list()\n",
    "ICols = enum.IntEnum('ICols', icols, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row_id',\n",
       " 'timestamp',\n",
       " 'user_id',\n",
       " 'content_id',\n",
       " 'content_type_id',\n",
       " 'task_container_id',\n",
       " 'user_answer',\n",
       " 'answered_correctly',\n",
       " 'prior_question_elapsed_time',\n",
       " 'prior_question_had_explanation']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "icodes_d = {}\n",
    "for col, cats in icats.items():\n",
    "    # code=0 is reserved for <NA>, NaN and the likes\n",
    "    icodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack in <NA> in cats_d['prior_question_had_explanation']\n",
    "icodes_d['prior_question_had_explanation'][pd.NA] = 0\n",
    "icodes_d['prior_question_had_explanation'][np.nan] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_icode = max([ max(col_codes.values()) for col_codes in icodes_d.values() ])\n",
    "assert max_icode < 2**15 # fit in int16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all codes into codes_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_d = { **icodes_d, **qcodes_d, **lcodes_d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = sorted([\n",
    "    'already_answered',          # has this question been answered before?\n",
    "    'answered_correctly',        # answered correctly by user\n",
    "    'bundle_id', \n",
    "    'correct_answer', \n",
    "    'lecture_id', \n",
    "    'part', \n",
    "    'qhe',                       # question has explanation (pqhe shifted upwards 1 container)\n",
    "    'question_id', \n",
    "    'task_container_id',\n",
    "    'type_of',                   # lecture type\n",
    "    'user_answer', \n",
    "])\n",
    "\n",
    "# To hide from decoder:\n",
    "# - answered_correctly\n",
    "# - user_answer\n",
    "# - qhe\n",
    "\n",
    "cont_names = sorted([\n",
    "    'attempt_num',               # number of attempts per user_id, question_id\n",
    "    'attempt_num_log',           # log1p of the above\n",
    "    'attempts_correct',          # number of CORRECT attempts per user_id, question_id\n",
    "    'attempts_correct_log',\n",
    "    'attempts_correct_avg',      # attempts_correct / attempts_num\n",
    "    'attempts_correct_avg_log',\n",
    "    'container_ord',             # ordinal of question within container\n",
    "    'qet',                       # question elapsed time (pqet shifted upwards 1 container)\n",
    "    'qet_log',\n",
    "    'qp',                        # probabilty of occurrence of this question\n",
    "    'qp_log',\n",
    "    'timestamp',                 # interaction ts\n",
    "    'timestamp_log',\n",
    "    'tsli',                      # time since last interaction (aka timestamp delta)\n",
    "    'tsli_log',\n",
    "    'clipped_tsli',              # tsli clipped to 20 minutes\n",
    "    'clipped_tsli_log',\n",
    "    'ts_mod_1day',               # timestamp modulus 1 day\n",
    "    'ts_mod_1day_sin',\n",
    "    'ts_mod_1day_cos',\n",
    "    'ts_mod_1week',              # timestamp modulus 1 week\n",
    "    'ts_mod_1week_sin',\n",
    "    'ts_mod_1week_cos',\n",
    "])\n",
    "\n",
    "# To hide from decoder:\n",
    "# - qet\n",
    "# - qet_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cats = enum.IntEnum('Cats', cat_names, start=0)\n",
    "Conts = enum.IntEnum('Conts', cont_names, start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode user_ids\n",
    "This helps coo -> lil_matrix conversion to not freak out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_d = defaultdict(lambda: len(users_d))\n",
    "for user_id in np.sort(i_df.user_id.unique()):\n",
    "    users_d[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(users_d.keys()) == 393656\n",
    "assert np.all(np.array(list(users_d.keys())) == np.array(sorted(users_d.keys())))\n",
    "assert users_d[2746] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find probabilty of occurrence of each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 s, sys: 922 ms, total: 5.24 s\n",
      "Wall time: 5.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp_q_df = i_df[i_df.content_type_id == 0]\n",
    "qp_d = (tmp_q_df.content_id.value_counts() / len(tmp_q_df)).to_dict()\n",
    "del tmp_q_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `update_questions`, `update_answers`, `get_x` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_questions(df, Col, cat_names, cont_names, qc_d, lc_d, codes_d, QCols, LCols, Cats, Conts, \n",
    "        hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, last_q_container_d, last_ts, attempt_num, \n",
    "        attempts_correct, qp_d, users_d):\n",
    "    \n",
    "    df_a = df.values\n",
    "    \n",
    "    n_rows = len(df)\n",
    "    \n",
    "    # Prefetch tslis per (user_id, tcid) for better_tsli calculation\n",
    "    # NOTE the keys (user_id, tcid) are NOT encoded\n",
    "    tsli_d = defaultdict(list)\n",
    "    #for i, (_, row) in enumerate(df_d.items()): # SLOW\n",
    "    #for i, (_, row) in enumerate(df.iterrows()): # SUPER SLOW\n",
    "    for i, row in enumerate(df_a):\n",
    "        user_id, tcid, ts = row[Col.user_id], row[Col.task_container_id], row[Col.timestamp]\n",
    "        encoded_user_id = users_d[user_id]\n",
    "        tsli_d[user_id, tcid].append(ts - last_ts[encoded_user_id,0])\n",
    "        last_ts[encoded_user_id,0] = np.int64(ts)\n",
    "        \n",
    "    # average all tslis in the same task container\n",
    "    tsli_d = { k: sum(v)/len(v) for k, v in tsli_d.items() }\n",
    "    \n",
    "    # append df data to history\n",
    "    for i, row in enumerate(df_a):\n",
    "        user_id = row[Col.user_id]\n",
    "        encoded_user_id = users_d[user_id]\n",
    "        user_has_hist = user_id in hist_cat_d\n",
    "        if user_has_hist:\n",
    "            h_cat  = hist_cat_d [user_id] # just shortcuts\n",
    "            h_cont = hist_cont_d[user_id]\n",
    "            h_tags = hist_tags_d[user_id]\n",
    "            h_tagw = hist_tagw_d[user_id]\n",
    "        \n",
    "        cat  = np.zeros(len(cat_names),  dtype=np.int16)\n",
    "        cont = np.full (len(cont_names), np.nan, dtype=np.float32)\n",
    "\n",
    "        # Categorical test data\n",
    "        content_id = row[Col.content_id]\n",
    "        is_question = row[Col.content_type_id] == 0\n",
    "\n",
    "        if is_question:\n",
    "            encoded_question_id = codes_d['question_id'][content_id]\n",
    "            qc_row = qc_d[encoded_question_id]\n",
    "            cat[Cats.bundle_id]        = qc_row[QCols.bundle_id]\n",
    "            cat[Cats.correct_answer]   = qc_row[QCols.correct_answer]\n",
    "            cat[Cats.part]             = qc_row[QCols.part]\n",
    "            cat[Cats.question_id]      = encoded_question_id\n",
    "            cat[Cats.already_answered] = (int)(attempt_num[encoded_user_id, encoded_question_id-1] > 0)\n",
    "            cat[Cats.qhe]              = 0  # question has explanation?, not known yet    \n",
    "        else:\n",
    "            encoded_lecture_id = codes_d['lecture_id'][content_id]\n",
    "            lc_row = lc_d[encoded_lecture_id]\n",
    "            cat[Cats.lecture_id] = encoded_lecture_id\n",
    "            cat[Cats.part]       = lc_row[LCols.part]\n",
    "            cat[Cats.type_of]    = lc_row[LCols.type_of]\n",
    "\n",
    "        tcid = row[Col.task_container_id]\n",
    "        encoded_pqhe = codes_d['prior_question_had_explanation'][row[Col.prior_question_had_explanation]]\n",
    "        encoded_tcid = codes_d['task_container_id'][tcid]\n",
    "        cat[Cats.task_container_id] = encoded_tcid\n",
    "        \n",
    "        # Continuous test data\n",
    "        ts = row[Col.timestamp]\n",
    "        ts_mod_1day = ts % (1000 * 60 * 60 * 24)\n",
    "        ts_mod_1week = ts % (1000 * 60 * 60 * 24 * 7)\n",
    "        pqet = row[Col.prior_question_elapsed_time]\n",
    "        tsli = tsli_d[(user_id, tcid)] if user_has_hist else np.nan\n",
    "        clipped_tsli = min(tsli, 1000 * 60 * 20) # 20 minutes\n",
    "        \n",
    "        cont[Conts.qet]              = np.nan\n",
    "        cont[Conts.timestamp]        = ts\n",
    "        cont[Conts.tsli]             = tsli\n",
    "        cont[Conts.clipped_tsli]     = clipped_tsli\n",
    "        cont[Conts.qet_log]          = np.nan\n",
    "        cont[Conts.timestamp_log]    = np.log1p(ts)\n",
    "        cont[Conts.tsli_log]         = np.log1p(tsli)\n",
    "        cont[Conts.clipped_tsli_log] = np.log1p(clipped_tsli)\n",
    "        cont[Conts.ts_mod_1day]      = ts_mod_1day\n",
    "        cont[Conts.ts_mod_1day_sin]  = np.sin(ts_mod_1day * 2 * np.pi / (1000 * 60 * 60 * 24))\n",
    "        cont[Conts.ts_mod_1day_cos]  = np.cos(ts_mod_1day * 2 * np.pi / (1000 * 60 * 60 * 24))\n",
    "        cont[Conts.ts_mod_1week]     = ts_mod_1week\n",
    "        cont[Conts.ts_mod_1week_sin] = np.sin(ts_mod_1week * 2 * np.pi / (1000 * 60 * 60 * 24 * 7))\n",
    "        cont[Conts.ts_mod_1week_cos] = np.cos(ts_mod_1week * 2 * np.pi / (1000 * 60 * 60 * 24 * 7))\n",
    "        \n",
    "        # container ordinal\n",
    "        if user_has_hist and h_cat[-1,Cats.task_container_id] == encoded_tcid:\n",
    "            cont[Conts.container_ord] = h_cont[-1,Conts.container_ord] + 1\n",
    "        else:\n",
    "            cont[Conts.container_ord] = 0\n",
    "        \n",
    "        if is_question:\n",
    "            # Update qet and qet_log in history (make qet in last bundle skipping lectures = pqet)\n",
    "            if user_id in last_q_container_d and encoded_tcid != last_q_container_d[user_id]:\n",
    "                idx = h_cat[:,Cats.task_container_id] == last_q_container_d[user_id]\n",
    "                h_cat [idx,Cats.qhe]      = encoded_pqhe\n",
    "                h_cont[idx,Conts.qet]     = pqet\n",
    "                h_cont[idx,Conts.qet_log] = np.log1p(pqet)\n",
    "                        \n",
    "            last_q_container_d[user_id] = encoded_tcid\n",
    "            \n",
    "            # Update attempt_num\n",
    "            an = attempt_num     [encoded_user_id, encoded_question_id-1] # np.uint8\n",
    "            ac = attempts_correct[encoded_user_id, encoded_question_id-1] # np.uint8\n",
    "            cont[Conts.attempt_num]              = an\n",
    "            cont[Conts.attempt_num_log]          = np.log1p(an)\n",
    "            \n",
    "            # Update attempts_correct with what we know so far (will be re-updated after we've got the answers)\n",
    "            cont[Conts.attempts_correct]         = ac\n",
    "            cont[Conts.attempts_correct_log]     = np.log1p(ac)\n",
    "            if an != 0:\n",
    "                cont[Conts.attempts_correct_avg]     = ac / an\n",
    "                cont[Conts.attempts_correct_avg_log] = np.log1p(ac / an)\n",
    "\n",
    "            attempt_num[encoded_user_id, encoded_question_id-1] += np.uint8(1)\n",
    "\n",
    "            # question occurrence prob\n",
    "            cont[Conts.qp]              = qp_d[content_id] # qp_d indexes are non-encoded qids\n",
    "            cont[Conts.qp_log]          = np.log1p(cont[Conts.qp])\n",
    "\n",
    "        # Tags and weights\n",
    "        if is_question:\n",
    "            tags = qc_row[[ QCols.tag_0, QCols.tag_1, QCols.tag_2, QCols.tag_3, QCols.tag_4, QCols.tag_5 ]]\n",
    "        else:\n",
    "            tags = lc_row[[ LCols.tag_0, LCols.tag_1, LCols.tag_2, LCols.tag_3, LCols.tag_4, LCols.tag_5 ]]\n",
    "        tags = tags.astype(np.uint8)\n",
    "        tagw = (tags != 0).astype(np.float16)\n",
    "        sums = tagw.sum()\n",
    "        if sums > 0:\n",
    "            tagw /= sums\n",
    "       \n",
    "        # Concat history and new test data\n",
    "        if user_has_hist:\n",
    "            hist_cat_d [user_id] = np.concatenate((h_cat,  np.expand_dims(cat,  0)))\n",
    "            hist_cont_d[user_id] = np.concatenate((h_cont, np.expand_dims(cont, 0)))\n",
    "            hist_tags_d[user_id] = np.concatenate((h_tags, np.expand_dims(tags, 0)))\n",
    "            hist_tagw_d[user_id] = np.concatenate((h_tagw, np.expand_dims(tagw, 0)))\n",
    "        else:\n",
    "            hist_cat_d [user_id] = np.expand_dims(cat,  0)\n",
    "            hist_cont_d[user_id] = np.expand_dims(cont, 0)\n",
    "            hist_tags_d[user_id] = np.expand_dims(tags, 0)\n",
    "            hist_tagw_d[user_id] = np.expand_dims(tagw, 0)\n",
    "\n",
    "    return df.user_id.values\n",
    "\n",
    "\n",
    "def update_answers(prior_user_ids, prior_group_answers_correct, prior_group_responses, \n",
    "        cat_names, cont_names, codes_d, hist_cat_d, hist_cont_d, users_d, attempt_num, attempts_correct):\n",
    "\n",
    "    idx_per_uid_d = defaultdict(int)\n",
    "    for uid in prior_user_ids:\n",
    "        idx_per_uid_d[uid] -= 1\n",
    "\n",
    "    for i, uid in enumerate(prior_user_ids):\n",
    "        h_cat  = hist_cat_d [uid] # just shortcuts\n",
    "        h_cont = hist_cont_d[uid]\n",
    "        \n",
    "        idx = idx_per_uid_d[uid]\n",
    "        idx_per_uid_d[uid] += 1\n",
    "        \n",
    "        # Update categorical vars\n",
    "        h_cat [idx,Cats.answered_correctly] = codes_d['answered_correctly'][prior_group_answers_correct[i]]\n",
    "        h_cat [idx,Cats.user_answer]        = codes_d['user_answer'][prior_group_responses[i]]\n",
    "\n",
    "        # Update continuous vars\n",
    "        eqid = h_cat[idx,Cats.question_id]\n",
    "        if eqid > 0: # it's a question\n",
    "            assert prior_group_answers_correct[i] >= 0\n",
    "            euid = users_d[uid]\n",
    "            ac = attempts_correct[euid,eqid-1] # np.int8\n",
    "            an = h_cont[idx,Conts.attempt_num] # np.float32\n",
    "            h_cont[idx,Conts.attempts_correct]         = ac\n",
    "            h_cont[idx,Conts.attempts_correct_log]     = np.log1p(ac)\n",
    "            if an != 0:\n",
    "                h_cont[idx,Conts.attempts_correct_avg]     = ac / an\n",
    "                h_cont[idx,Conts.attempts_correct_avg_log] = np.log1p(ac / an)\n",
    "\n",
    "            attempts_correct[euid,eqid-1] = ac + np.uint8(prior_group_answers_correct[i])\n",
    "        else:\n",
    "            assert prior_group_answers_correct[i] == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```proxy_append_df```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_append_df(df):\n",
    "    hist_cat_d         = {}\n",
    "    hist_cont_d        = {}\n",
    "    hist_tags_d        = {}\n",
    "    hist_tagw_d        = {}\n",
    "    last_q_container_d = {}\n",
    "    last_ts            = defaultdict(np.int64)\n",
    "    attempt_num        = defaultdict(np.uint8)\n",
    "    attempts_correct   = defaultdict(np.uint8)\n",
    "    chunk_size         = None\n",
    "    Col                = enum.IntEnum('Col', df.columns.tolist(), start=0)\n",
    "\n",
    "    # update questions\n",
    "    prior_user_ids = update_questions(\n",
    "        df, Col, cat_names, cont_names, qc_d, lc_d, codes_d, QCols, LCols, Cats, Conts, \n",
    "        hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, last_q_container_d, last_ts, \n",
    "        attempt_num, attempts_correct, qp_d, users_d)\n",
    "\n",
    "    # update answers\n",
    "    prior_group_answers_correct = df.answered_correctly.values\n",
    "    prior_group_responses       = df.user_answer.values\n",
    "\n",
    "    update_answers(prior_user_ids, prior_group_answers_correct, prior_group_responses, \n",
    "        cat_names, cont_names, codes_d, hist_cat_d, hist_cont_d, users_d, attempt_num, attempts_correct)\n",
    "    \n",
    "    return (hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, \n",
    "            last_q_container_d, last_ts, attempt_num, attempts_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `append_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f update_answers (\n",
    "#    hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, \n",
    "#    last_last_q_container_d, last_ts, attempt_num, previous_ac) = proxy_append_df(i_df[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#(hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d,\n",
    "# last_last_q_container_d, last_ts, attempt_num, attempts_correct) = proxy_append_df(i_df[:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pytorch.sparse -> 32s and can't parallelize (\"torch sparse tensor has no storage\" error)\n",
    "* scipy.sparse.dok_matrix -> 17.5s\n",
    "* scipy.sparse.lil_matrix -> 15.4s\n",
    "* scipy.sparse.csr_matrix -> minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 1000)\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting user_ids:\n",
    "\n",
    "- 8623 (3 containers x 5 questions)\n",
    "- 124 (1 container, meaningful tsli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_df[i_df.user_id == 8623]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(hist_ord_d[8623], columns=['ordinal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(hist_cat_d[8623], columns=cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for the header\n",
    "#pd.DataFrame(hist_cont_d[8623][:1], columns=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = pd.DataFrame(hist_cont_d[8623], columns=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df[test_df.attempt_num > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_cont = np.concatenate(list(v for v in hist_cont_d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_=plt.hist(np.log1p(all_cont[:,Conts.tsli]), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.exp(14) / 1000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(hist_cat_d[124], columns=cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(hist_cont_d[115], columns=cont_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(i_df.user_id.min()-1, i_df.user_id.max(), num=1024+1, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = i_df.groupby(pd.cut(i_df.user_id, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 1.68 s, total: 7.68 s\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "groups = [ dfg.get_group(_) for _ in dfg.groups.keys() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [15:23<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor() as e:\n",
    "    res = list(tqdm(e.map(proxy_append_df, groups), total=len(groups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 28.3 s, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merge_dicts = lambda idx: { k: v for d in [ _[idx] for _ in res ] for k, v in d.items() }\n",
    "cat_d                 = merge_dicts(0)\n",
    "cont_d                = merge_dicts(1)\n",
    "tags_d                = merge_dicts(2)\n",
    "tagw_d                = merge_dicts(3)\n",
    "last_q_container_id_d = merge_dicts(4)\n",
    "last_ts               = merge_dicts(5)\n",
    "attempt_num           = merge_dicts(6)\n",
    "attempts_correct      = merge_dicts(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dok matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(v.dtype == np.int64 for v in last_ts.values())\n",
    "assert all(v.dtype == np.uint8 for v in attempt_num.values())\n",
    "assert all(v.dtype == np.uint8 for v in attempts_correct.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ts_dok          = dok_matrix((H.max_users, 1), dtype=np.int64)\n",
    "attempt_num_dok      = dok_matrix((H.max_users, H.max_questions), dtype=np.uint8)\n",
    "attempts_correct_dok = dok_matrix((H.max_users, H.max_questions), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ts_dok._update(last_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_num_dok._update(attempt_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_correct_dok._update(attempts_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del res  # this barely has an effect\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dok -> array or coo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<450000x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 393656 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_ts_dok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.6 ms, sys: 4.08 ms, total: 101 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "last_ts = last_ts_dok.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<450000x13523 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 86867031 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attempt_num_dok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 3.01 s, total: 24.5 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "attempt_num_coo = attempt_num_dok.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<450000x13523 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 86867031 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attempts_correct_dok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 1.44 s, total: 16.6 s\n",
      "Wall time: 16.6 s\n",
      "Compiler : 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "attempts_correct_coo = attempts_correct_dok.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del attempt_num, attempts_correct\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(last_q_container_id_d) == len(cat_d) == len(i_df.user_id.unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert attempt_num_coo.getnnz() == 86867031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts = i_df.groupby('user_id')['timestamp'].max().values\n",
    "np.testing.assert_equal(test_ts, last_ts[:len(test_ts),0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb = {\n",
    "    'already_answered': 2,\n",
    "    'answered_correctly': 4,\n",
    "    'bundle_id': 9766,\n",
    "    'correct_answer': 5,\n",
    "    'lecture_id': 419,\n",
    "    'part': 8,\n",
    "    'prior_question_had_explanation': 3,\n",
    "    'question_id': 13524,\n",
    "    'task_container_id': 10001,\n",
    "    'type_of': 5,\n",
    "    'user_answer': 6\n",
    "}\n",
    "\n",
    "emb_dim = {\n",
    "    'already_answered': 1,\n",
    "    'answered_correctly': 3,\n",
    "    'bundle_id': 274,\n",
    "    'correct_answer': 4,\n",
    "    'lecture_id': 47,\n",
    "    'part': 5,\n",
    "    'prior_question_had_explanation': 3,\n",
    "    'question_id': 329,\n",
    "    'task_container_id': 278,\n",
    "    'type_of': 4,\n",
    "    'user_answer': 4\n",
    "}\n",
    "\n",
    "tags_n_emb = 187+2 # [0..max_tag, max_tag+1]. max_tag+1 = empty tag \n",
    "tags_emb_dim = tags_n_emb # emb_sz_rule(tags_n_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cat = np.concatenate(list(cat_d.values()))\n",
    "assert np.isnan(all_cat).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tags_d[115].dtype == np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Means and stds of continuous vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cont = np.concatenate(list(cont_d.values()))\n",
    "assert all_cont.shape[0] == len(i_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.nanmax(all_cont[:,Conts.attempt_num]) == 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert np.isnan(all_cont[:,Conts.prior_question_elapsed_time]).sum() == i_df.prior_question_elapsed_time.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.nanmean(all_cont, axis=0, dtype=np.float64)\n",
    "stds  = np.nanstd (all_cont, axis=0, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = np.nanmax(all_cont, axis=0)\n",
    "mins = np.nanmin(all_cont, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['attempt_num',\n",
       "  'attempt_num_log',\n",
       "  'attempts_correct',\n",
       "  'attempts_correct_avg',\n",
       "  'attempts_correct_avg_log',\n",
       "  'attempts_correct_log',\n",
       "  'clipped_tsli',\n",
       "  'clipped_tsli_log',\n",
       "  'container_ord',\n",
       "  'qet',\n",
       "  'qet_log',\n",
       "  'qp',\n",
       "  'qp_log',\n",
       "  'timestamp',\n",
       "  'timestamp_log',\n",
       "  'ts_mod_1day',\n",
       "  'ts_mod_1day_cos',\n",
       "  'ts_mod_1day_sin',\n",
       "  'ts_mod_1week',\n",
       "  'ts_mod_1week_cos',\n",
       "  'ts_mod_1week_sin',\n",
       "  'tsli',\n",
       "  'tsli_log'],\n",
       " array([1.71275676e-01, 1.02451578e-01, 6.78789338e-02, 3.60193529e-01,\n",
       "        2.56868295e-01, 4.17399861e-02, 1.62953342e+05, 1.10097465e+01,\n",
       "        4.04873294e-01, 2.59525175e+04, 9.92678915e+00, 2.54023347e-04,\n",
       "        2.53917140e-04, 7.70364365e+09, 2.08774076e+01, 3.85844342e+07,\n",
       "        2.39129433e-01, 1.60690095e-02, 2.58239902e+08, 1.16058160e-01,\n",
       "        5.14945556e-02, 2.00618321e+07, 1.12457744e+01]),\n",
       " array([5.84928336e-01, 2.86078097e-01, 3.70166409e-01, 4.47063082e-01,\n",
       "        3.12723449e-01, 1.84429290e-01, 3.23172954e+05, 1.19666667e+00,\n",
       "        8.40763914e-01, 2.04180510e+04, 8.28739183e-01, 3.84824433e-04,\n",
       "        3.84496934e-04, 1.15926553e+10, 3.33278846e+00, 2.89322120e+07,\n",
       "        7.21060451e-01, 6.50100564e-01, 1.87675544e+08, 7.32093081e-01,\n",
       "        6.69267159e-01, 4.68762026e+08, 1.94163643e+00]),\n",
       " array([8.2000000e+01, 4.4179688e+00, 8.2000000e+01, 1.0000000e+00,\n",
       "        6.9314718e-01, 4.4179688e+00, 1.2000000e+06, 1.3997833e+01,\n",
       "        9.0000000e+00, 3.0000000e+05, 1.2611541e+01, 2.1517295e-03,\n",
       "        2.1494180e-03, 8.7425769e+10, 2.5194056e+01, 8.6400000e+07,\n",
       "        1.0000000e+00, 1.0000000e+00, 6.0480000e+08, 1.0000000e+00,\n",
       "        1.0000000e+00, 8.3884261e+10, 2.5152704e+01], dtype=float32),\n",
       " array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0073405e-08,\n",
       "         1.0073405e-08,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n",
       "        -1.0000000e+00,  0.0000000e+00,  0.0000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names, means, stds, maxs, mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20061832.085879758"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[Conts.tsli]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(means[Conts.timestamp] - 7703643654.326523) < 0.1 # vs 52\n",
    "#assert np.abs(means[Conts.prior_question_elapsed_time] - 25423.844) < 0.1 # vs 52\n",
    "assert np.abs(means[Conts.tsli] - 20061832.08) < 50 # vs 201221 (precise timestamp)\n",
    "assert np.abs(means[Conts.qet] - 2.59525175e+04) < 0.1 # vs 62, TODO: fix bundle_id -> tcid in 52 and get baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(all_cont[:100], columns=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(all_cat[:100], columns=cat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WTF, can't pickle enums... We'll rebuild them at train/infer\n",
    "```\n",
    "QCols = enum.IntEnum('QCols', meta.qcols, start=0)\n",
    "LCols = enum.IntEnum('LCols', meta.lcols, start=0)\n",
    "Cats  = enum.IntEnum('Cats',  meta.cat_names, start=0)\n",
    "Conts = enum.IntEnum('Conts', meta.cont_names, start=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = _H(\n",
    "    means=means,\n",
    "    stds=stds,\n",
    "    maxs=maxs,\n",
    "    mins=mins,\n",
    "    qc_d=qc_d,\n",
    "    qcats=qcats,\n",
    "    qcols=qcols,\n",
    "    qcodes_d=qcodes_d,\n",
    "    lc_d=lc_d,\n",
    "    lcats=lcats,\n",
    "    lcols=lcols,\n",
    "    lcodes_d=lcodes_d,\n",
    "    codes_d=codes_d,\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    icats=icats,\n",
    "    n_emb=n_emb,\n",
    "    emb_dim=emb_dim,\n",
    "    tags_n_emb=tags_n_emb,\n",
    "    tags_emb_dim=tags_emb_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _H(\n",
    "    cat_d=cat_d,\n",
    "    cont_d=cont_d,\n",
    "    tags_d=tags_d,\n",
    "    tagw_d=tagw_d,\n",
    "    last_q_contained_id_d=last_q_container_id_d,\n",
    "    attempt_num_coo=attempt_num_coo,\n",
    "    attempts_correct_coo=attempts_correct_coo,\n",
    "    last_ts=last_ts,\n",
    "    qp_d=qp_d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'210101b'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 3s, sys: 1min 13s, total: 6min 16s\n",
      "Wall time: 6min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(in_d / f'data_v{H.version}.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 63.5 ms, total: 179 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(in_d / f'meta_v{H.version}.pkl', 'wb') as f:\n",
    "    pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai==2.0.15\n",
      "  Downloading fastai-2.0.15-py3-none-any.whl (185 kB)\n",
      "\u001b[K     |████████████████████████████████| 185 kB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (3.2.1)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (1.5.2)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (2.26.0)\n",
      "Requirement already satisfied: torchvision>=0.7 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (0.8.2)\n",
      "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (0.22.2.post1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (1.0.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (1.7.1)\n",
      "Requirement already satisfied: pip in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (20.1.1)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (5.4.1)\n",
      "Requirement already satisfied: pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (8.0.0)\n",
      "Requirement already satisfied: spacy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (2.1.8)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (1.1.5)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (21.0)\n",
      "Requirement already satisfied: fastcore>=1.0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai==2.0.15) (1.3.27)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==2.0.15) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==2.0.15) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==2.0.15) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==2.0.15) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai==2.0.15) (1.18.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==2.0.15) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==2.0.15) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==2.0.15) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai==2.0.15) (2.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn->fastai==2.0.15) (0.14.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch>=1.6.0->fastai==2.0.15) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch>=1.6.0->fastai==2.0.15) (3.10.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (0.2.4)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (2.0.1)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai==2.0.15) (7.0.8)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai==2.0.15) (2021.1)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->fastai==2.0.15) (1.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.8->spacy->fastai==2.0.15) (4.62.2)\n",
      "Installing collected packages: fastai\n",
      "  Attempting uninstall: fastai\n",
      "    Found existing installation: fastai 2.2.5\n",
      "    Uninstalling fastai-2.2.5:\n",
      "      Successfully uninstalled fastai-2.2.5\n",
      "Successfully installed fastai-2.0.15\n",
      "Collecting fastai2==0.0.30\n",
      "  Downloading fastai2-0.0.30-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (21.0)\n",
      "Requirement already satisfied: pip in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (20.1.1)\n",
      "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (0.22.2.post1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (1.7.1)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (2.26.0)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (3.2.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (1.0.0)\n",
      "Requirement already satisfied: fastcore>=0.1.34 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (1.3.27)\n",
      "Requirement already satisfied: pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (8.0.0)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (1.5.2)\n",
      "Requirement already satisfied: torchvision>=0.7 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (0.8.2)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (5.4.1)\n",
      "Requirement already satisfied: pandas in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (1.1.5)\n",
      "Requirement already satisfied: spacy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai2==0.0.30) (2.1.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai2==0.0.30) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn->fastai2==0.0.30) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn->fastai2==0.0.30) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch>=1.6.0->fastai2==0.0.30) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from torch>=1.6.0->fastai2==0.0.30) (0.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai2==0.0.30) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai2==0.0.30) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai2==0.0.30) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai2==0.0.30) (1.25.11)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai2==0.0.30) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai2==0.0.30) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai2==0.0.30) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai2==0.0.30) (2021.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (0.2.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (0.9.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (2.0.5)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (7.0.8)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (2.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy->fastai2==0.0.30) (0.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->fastai2==0.0.30) (1.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.8->spacy->fastai2==0.0.30) (4.62.2)\n",
      "Installing collected packages: fastai2\n",
      "Successfully installed fastai2-0.0.30\n",
      "Collecting fastcore==1.0.16.\n",
      "  Downloading fastcore-1.0.16-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 3.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastcore==1.0.16.) (21.0)\n",
      "Requirement already satisfied: pip in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastcore==1.0.16.) (20.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastcore==1.0.16.) (2.4.7)\n",
      "Installing collected packages: fastcore\n",
      "  Attempting uninstall: fastcore\n",
      "    Found existing installation: fastcore 1.3.27\n",
      "    Uninstalling fastcore-1.3.27:\n",
      "      Successfully uninstalled fastcore-1.3.27\n",
      "Successfully installed fastcore-1.0.16\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai==2.0.15\n",
    "!pip install fastai2==0.0.30\n",
    "!pip install fastcore==1.0.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-af1f7fb2dc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.13.0\n",
      "adal==1.2.7\n",
      "aiohttp==3.7.4.post0\n",
      "aiohttp-cors==0.7.0\n",
      "aioredis==1.3.1\n",
      "ansiwrap==0.8.4\n",
      "antlr4-python3-runtime==4.7.2\n",
      "anyio==3.3.1\n",
      "applicationinsights==0.11.10\n",
      "arch==4.14\n",
      "argcomplete==1.12.3\n",
      "argon2-cffi==21.1.0\n",
      "astor==0.8.1\n",
      "astroid==2.8.0\n",
      "astunparse==1.6.3\n",
      "async-timeout==3.0.1\n",
      "attrs==21.2.0\n",
      "autokeras==1.0.16\n",
      "autopep8==1.5.7\n",
      "azure-appconfiguration==1.1.1\n",
      "azure-batch==10.0.0\n",
      "azure-cli==2.24.0\n",
      "azure-cli-core==2.24.0\n",
      "azure-cli-telemetry==1.0.6\n",
      "azure-common==1.1.27\n",
      "azure-core==1.18.0\n",
      "azure-cosmos==3.2.0\n",
      "azure-datalake-store==0.0.52\n",
      "azure-functions-devops-build==0.0.22\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.4.1\n",
      "azure-keyvault==1.1.0\n",
      "azure-keyvault-administration==4.0.0b3\n",
      "azure-loganalytics==0.1.0\n",
      "azure-mgmt-advisor==2.0.1\n",
      "azure-mgmt-apimanagement==0.2.0\n",
      "azure-mgmt-appconfiguration==1.0.1\n",
      "azure-mgmt-applicationinsights==0.1.1\n",
      "azure-mgmt-authorization==0.61.0\n",
      "azure-mgmt-batch==9.0.0\n",
      "azure-mgmt-batchai==2.0.0\n",
      "azure-mgmt-billing==1.0.0\n",
      "azure-mgmt-botservice==0.3.0\n",
      "azure-mgmt-cdn==11.0.0\n",
      "azure-mgmt-cognitiveservices==6.3.0\n",
      "azure-mgmt-compute==20.0.0\n",
      "azure-mgmt-consumption==2.0.0\n",
      "azure-mgmt-containerinstance==1.5.0\n",
      "azure-mgmt-containerregistry==8.1.0\n",
      "azure-mgmt-containerservice==11.2.0\n",
      "azure-mgmt-core==1.3.0\n",
      "azure-mgmt-cosmosdb==6.3.0\n",
      "azure-mgmt-databoxedge==0.2.0\n",
      "azure-mgmt-datalake-analytics==0.2.1\n",
      "azure-mgmt-datalake-nspkg==3.0.1\n",
      "azure-mgmt-datalake-store==0.5.0\n",
      "azure-mgmt-datamigration==4.1.0\n",
      "azure-mgmt-deploymentmanager==0.2.0\n",
      "azure-mgmt-devtestlabs==4.0.0\n",
      "azure-mgmt-dns==8.0.0\n",
      "azure-mgmt-eventgrid==3.0.0rc9\n",
      "azure-mgmt-eventhub==4.1.0\n",
      "azure-mgmt-hdinsight==2.2.0\n",
      "azure-mgmt-imagebuilder==0.4.0\n",
      "azure-mgmt-iotcentral==4.1.0\n",
      "azure-mgmt-iothub==2.0.0\n",
      "azure-mgmt-iothubprovisioningservices==0.2.0\n",
      "azure-mgmt-keyvault==9.1.0\n",
      "azure-mgmt-kusto==0.3.0\n",
      "azure-mgmt-loganalytics==8.0.0\n",
      "azure-mgmt-managedservices==1.0.0\n",
      "azure-mgmt-managementgroups==0.2.0\n",
      "azure-mgmt-maps==0.1.0\n",
      "azure-mgmt-marketplaceordering==1.1.0\n",
      "azure-mgmt-media==3.1.0\n",
      "azure-mgmt-monitor==2.0.0\n",
      "azure-mgmt-msi==0.2.0\n",
      "azure-mgmt-netapp==2.0.0\n",
      "azure-mgmt-network==19.0.0\n",
      "azure-mgmt-nspkg==3.0.2\n",
      "azure-mgmt-policyinsights==0.5.0\n",
      "azure-mgmt-privatedns==1.0.0\n",
      "azure-mgmt-rdbms==8.1.0\n",
      "azure-mgmt-recoveryservices==0.4.0\n",
      "azure-mgmt-recoveryservicesbackup==0.11.0\n",
      "azure-mgmt-redhatopenshift==0.1.0\n",
      "azure-mgmt-redis==7.0.0\n",
      "azure-mgmt-relay==0.1.0\n",
      "azure-mgmt-reservations==0.6.0\n",
      "azure-mgmt-resource==13.0.0\n",
      "azure-mgmt-search==8.0.0\n",
      "azure-mgmt-security==0.6.0\n",
      "azure-mgmt-servicebus==6.0.0\n",
      "azure-mgmt-servicefabric==0.5.0\n",
      "azure-mgmt-servicefabricmanagedclusters==1.0.0\n",
      "azure-mgmt-signalr==0.4.0\n",
      "azure-mgmt-sql==0.26.0\n",
      "azure-mgmt-sqlvirtualmachine==0.5.0\n",
      "azure-mgmt-storage==11.2.0\n",
      "azure-mgmt-synapse==0.6.0\n",
      "azure-mgmt-trafficmanager==0.51.0\n",
      "azure-mgmt-web==2.0.0\n",
      "azure-multiapi-storage==0.6.2\n",
      "azure-nspkg==3.0.2\n",
      "azure-storage-blob==12.8.1\n",
      "azure-storage-common==1.4.2\n",
      "azure-storage-queue==12.1.6\n",
      "azure-synapse-accesscontrol==0.5.0\n",
      "azure-synapse-artifacts==0.6.0\n",
      "azure-synapse-spark==0.2.0\n",
      "azureml-accel-models==1.34.0\n",
      "azureml-automl-core==1.34.0\n",
      "azureml-automl-dnn-nlp==1.34.0\n",
      "azureml-automl-runtime==1.34.0\n",
      "azureml-cli-common==1.34.0\n",
      "azureml-contrib-automl-pipeline-steps==1.34.0\n",
      "azureml-contrib-dataset==1.34.0\n",
      "azureml-contrib-fairness==1.34.0\n",
      "azureml-contrib-notebook==1.34.0\n",
      "azureml-contrib-pipeline-steps==1.34.0\n",
      "azureml-contrib-reinforcementlearning==1.34.0\n",
      "azureml-contrib-server==1.34.0\n",
      "azureml-contrib-services==1.34.0\n",
      "azureml-core==1.34.0\n",
      "azureml-datadrift==1.34.0\n",
      "azureml-dataprep==2.22.2\n",
      "azureml-dataprep-native==38.0.0\n",
      "azureml-dataprep-rslex==1.20.1\n",
      "azureml-dataset-runtime==1.34.0\n",
      "azureml-defaults==1.34.0\n",
      "azureml-explain-model==1.34.0\n",
      "azureml-inference-server-http==0.3.1\n",
      "azureml-interpret==1.34.0\n",
      "azureml-mlflow==1.34.0\n",
      "azureml-opendatasets==1.34.0\n",
      "azureml-pipeline==1.34.0\n",
      "azureml-pipeline-core==1.34.0\n",
      "azureml-pipeline-steps==1.34.0\n",
      "azureml-responsibleai==1.34.0\n",
      "azureml-samples @ file:///mnt/jupyter-azsamples\n",
      "azureml-sdk==1.34.0\n",
      "azureml-telemetry==1.34.0\n",
      "azureml-tensorboard==1.34.0\n",
      "azureml-train==1.34.0\n",
      "azureml-train-automl==1.34.0\n",
      "azureml-train-automl-client==1.34.0\n",
      "azureml-train-automl-runtime==1.34.0\n",
      "azureml-train-core==1.34.0\n",
      "azureml-train-restclients-hyperdrive==1.34.0\n",
      "azureml-widgets==1.34.0\n",
      "backcall==0.2.0\n",
      "backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==3.2.0\n",
      "beautifulsoup4==4.10.0\n",
      "bleach==4.1.0\n",
      "blessings==1.7\n",
      "blis==0.2.4\n",
      "bokeh==2.3.3\n",
      "boto==2.49.0\n",
      "boto3==1.15.18\n",
      "botocore==1.18.18\n",
      "Bottleneck==1.3.2\n",
      "cached-property==1.5.2\n",
      "cachetools==4.2.2\n",
      "certifi==2021.5.30\n",
      "cffi==1.14.6\n",
      "chardet==4.0.0\n",
      "charset-normalizer==2.0.4\n",
      "click==8.0.1\n",
      "cloudpickle==1.6.0\n",
      "colorama==0.4.4\n",
      "colorful==0.5.4\n",
      "configparser==3.7.4\n",
      "contextlib2==21.6.0\n",
      "contextvars==2.4\n",
      "convertdate @ file:///home/conda/feedstock_root/build_artifacts/convertdate_1615678826465/work\n",
      "coremltools @ git+https://github.com/apple/coremltools@13c064ed99ab1da7abea0196e4ddf663ede48aad\n",
      "cryptography==3.4.8\n",
      "cycler==0.10.0\n",
      "cymem==2.0.5\n",
      "Cython==0.29.24\n",
      "dask==2.30.0\n",
      "databricks-cli==0.15.0\n",
      "dataclasses==0.8\n",
      "datasets==1.8.0\n",
      "decorator==5.0.9\n",
      "defusedxml==0.7.1\n",
      "dice-ml==0.6.1\n",
      "dill==0.3.4\n",
      "distributed==2.30.1\n",
      "distro==1.6.0\n",
      "dm-tree==0.1.6\n",
      "docker==5.0.2\n",
      "dotnetcore2==2.1.21\n",
      "dowhy==0.6\n",
      "econml==0.12.0\n",
      "en-core-web-sm @ https://aka.ms/automl-resources/packages/en_core_web_sm-2.1.0.tar.gz\n",
      "encrypted-inference==0.9\n",
      "entrypoints==0.3\n",
      "enum34==1.1.10\n",
      "erroranalysis==0.1.17\n",
      "fabric==2.6.0\n",
      "fairlearn==0.7.0\n",
      "fastai==2.0.15\n",
      "fastai2==0.0.30\n",
      "fastcore==1.0.16\n",
      "fastprogress==1.0.0\n",
      "fbprophet==0.5\n",
      "filelock==3.0.12\n",
      "fire==0.4.0\n",
      "flake8==3.9.2\n",
      "Flask==1.0.3\n",
      "Flask-Cors==3.0.10\n",
      "flatbuffers==2.0\n",
      "fsspec==2021.8.1\n",
      "fusepy==3.0.1\n",
      "future==0.18.2\n",
      "gast==0.2.2\n",
      "gensim==3.8.3\n",
      "gevent==1.3.6\n",
      "gitdb==4.0.7\n",
      "GitPython==3.1.18\n",
      "google-api-core==1.31.2\n",
      "google-auth==1.35.0\n",
      "google-auth-oauthlib==0.4.6\n",
      "google-pasta==0.2.0\n",
      "googleapis-common-protos==1.53.0\n",
      "gpustat==0.6.0\n",
      "graphviz @ file:///tmp/build/80754af9/python-graphviz_1602262908037/work\n",
      "greenlet==1.1.1\n",
      "grpcio==1.39.0\n",
      "gunicorn==20.1.0\n",
      "gym==0.20.0\n",
      "h5py==3.1.0\n",
      "HeapDict==1.0.1\n",
      "hiredis==2.0.0\n",
      "holidays==0.9.11\n",
      "horovod==0.19.1\n",
      "huggingface-hub==0.0.16\n",
      "humanfriendly==9.2\n",
      "idna==3.2\n",
      "idna-ssl==1.1.0\n",
      "imageio==2.9.0\n",
      "immutables==0.16\n",
      "importlib-metadata==4.8.1\n",
      "inference-schema==1.1.0\n",
      "interpret-community==0.19.3\n",
      "interpret-core==0.2.5\n",
      "invoke==1.6.0\n",
      "ipykernel==5.5.5\n",
      "ipython==7.16.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.6.4\n",
      "isodate==0.6.0\n",
      "isort==5.9.3\n",
      "itsdangerous==2.0.1\n",
      "javaproperties==0.5.1\n",
      "jedi==0.17.2\n",
      "jeepney==0.7.1\n",
      "Jinja2==2.11.2\n",
      "jmespath==0.10.0\n",
      "joblib==0.14.1\n",
      "jsmin==2.2.2\n",
      "json-logging-py==0.2\n",
      "json5==0.9.6\n",
      "jsondiff==1.2.0\n",
      "jsonpickle==2.0.0\n",
      "jsonschema==3.2.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==6.1.12\n",
      "jupyter-console==6.4.0\n",
      "jupyter-core==4.7.1\n",
      "jupyter-server==1.11.0\n",
      "jupyter-server-proxy==3.1.0\n",
      "jupyterlab==2.1.4\n",
      "jupyterlab-nvdashboard==0.5.0\n",
      "jupyterlab-server==1.2.0\n",
      "jupyterlab-widgets==1.0.1\n",
      "jupytext==1.6.0\n",
      "Keras==2.3.1\n",
      "Keras-Applications==1.0.8\n",
      "keras-nightly==2.5.0.dev2021032900\n",
      "Keras-Preprocessing==1.1.2\n",
      "keras-tuner==1.0.4\n",
      "keras2onnx==1.6.0\n",
      "kiwisolver==1.3.1\n",
      "knack==0.8.2\n",
      "kt-legacy==1.0.4\n",
      "lazy-object-proxy==1.6.0\n",
      "liac-arff==2.5.0\n",
      "lightgbm==2.3.0\n",
      "line-profiler==3.3.1\n",
      "llvmlite==0.36.0\n",
      "locket==0.2.1\n",
      "lunardate==0.2.0\n",
      "lz4==3.1.3\n",
      "Markdown==3.3.4\n",
      "markdown-it-py==0.5.8\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib @ file:///tmp/build/80754af9/matplotlib-base_1592406092619/work\n",
      "mccabe==0.6.1\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.2.0\n",
      "mkl-random==1.1.0\n",
      "mkl-service==2.3.0\n",
      "mlflow-skinny==1.20.2\n",
      "mock==4.0.3\n",
      "mpmath==1.2.1\n",
      "msal==1.14.0\n",
      "msal-extensions==0.2.2\n",
      "msgpack==1.0.2\n",
      "msrest==0.6.21\n",
      "msrestazure==0.6.4\n",
      "multidict==5.1.0\n",
      "multiprocess==0.70.12.2\n",
      "murmurhash==1.0.5\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.1.3\n",
      "nbresuse==0.4.0\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==2.5\n",
      "nimbusml==1.8.0\n",
      "notebook==6.4.3\n",
      "numba==0.53.1\n",
      "numexpr==2.7.3\n",
      "numpy==1.18.5\n",
      "nvidia-ml-py3==7.352.0\n",
      "oauthlib==3.1.1\n",
      "olefile==0.46\n",
      "onnx==1.7.0\n",
      "onnxconverter-common==1.6.0\n",
      "onnxmltools==1.4.1\n",
      "onnxruntime==1.8.0\n",
      "opencensus==0.7.13\n",
      "opencensus-context==0.1.2\n",
      "opencensus-ext-azure==1.0.8\n",
      "opencv-python-headless==4.5.3.56\n",
      "opt-einsum==3.3.0\n",
      "packaging==21.0\n",
      "pandas==1.1.5\n",
      "pandas-ml==0.6.1\n",
      "pandocfilters==1.4.3\n",
      "papermill==1.2.1\n",
      "paramiko==2.7.2\n",
      "parso==0.7.1\n",
      "partd==1.2.0\n",
      "pathlib2==2.3.6\n",
      "pathspec==0.9.0\n",
      "patsy==0.5.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow @ file:///tmp/build/80754af9/pillow_1602788709045/work\n",
      "pkginfo==1.7.1\n",
      "plac==0.9.6\n",
      "platformdirs==2.3.0\n",
      "plotly==5.3.1\n",
      "pluggy==1.0.0\n",
      "pmdarima==1.1.1\n",
      "portalocker==1.7.1\n",
      "preshed==2.0.1\n",
      "prometheus-client==0.11.0\n",
      "prompt-toolkit==3.0.20\n",
      "property-cached==1.6.4\n",
      "protobuf==3.17.3\n",
      "psutil==5.8.0\n",
      "psycopg2 @ file:///tmp/build/80754af9/psycopg2_1612298609104/work\n",
      "ptyprocess==0.7.0\n",
      "py-spy==0.3.9\n",
      "py4j==0.10.9\n",
      "pyarrow==3.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.0\n",
      "pycodestyle==2.6.0\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work\n",
      "pydocstyle==6.1.1\n",
      "pydot==1.4.2\n",
      "pyflakes==2.2.0\n",
      "PyGithub==1.38\n",
      "Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1629119114968/work\n",
      "PyJWT==2.1.0\n",
      "pylint==2.11.1\n",
      "PyMeeus @ file:///home/conda/feedstock_root/build_artifacts/pymeeus_1615809745702/work\n",
      "PyNaCl==1.4.0\n",
      "pynvml==11.0.0\n",
      "pyodbc===4.0.0-unsupported\n",
      "pyOpenSSL==20.0.1\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.18.0\n",
      "pyspark==3.1.2\n",
      "pystan==2.19.0.0\n",
      "pytesseract @ file:///home/conda/feedstock_root/build_artifacts/pytesseract_1622914748230/work\n",
      "python-dateutil==2.8.2\n",
      "python-jsonrpc-server==0.4.0\n",
      "python-language-server==0.35.0\n",
      "pytorch-transformers==1.0.0\n",
      "pytz==2021.1\n",
      "PyWavelets==1.1.1\n",
      "PyYAML==5.4.1\n",
      "pyzmq==22.2.1\n",
      "qtconsole==5.1.1\n",
      "QtPy==1.11.1\n",
      "QuantLib==1.23\n",
      "rai-core-flask==0.2.4\n",
      "raiwidgets==0.10.0\n",
      "ray==1.6.0\n",
      "redis==3.5.3\n",
      "regex==2021.8.28\n",
      "requests==2.26.0\n",
      "requests-oauthlib==1.3.0\n",
      "requests-unixsocket==0.2.0\n",
      "responsibleai==0.10.0\n",
      "rope==0.20.1\n",
      "rsa==4.7.2\n",
      "ruamel.yaml==0.17.4\n",
      "ruamel.yaml.clib==0.2.6\n",
      "s3transfer==0.3.7\n",
      "sacremoses==0.0.45\n",
      "scikit-image==0.17.2\n",
      "scikit-learn==0.22.2.post1\n",
      "scipy==1.5.2\n",
      "scp==0.13.6\n",
      "scrapbook==0.5.0\n",
      "seaborn==0.11.2\n",
      "SecretStorage==3.3.1\n",
      "semver==2.13.0\n",
      "Send2Trash==1.8.0\n",
      "sentencepiece==0.1.96\n",
      "seqeval==1.2.2\n",
      "setuptools-git==1.2\n",
      "shap==0.39.0\n",
      "simpervisor==0.4\n",
      "sip==4.19.24\n",
      "six==1.16.0\n",
      "skl2onnx==1.4.9\n",
      "sklearn==0.0\n",
      "sklearn-pandas==1.7.0\n",
      "slicer==0.0.7\n",
      "smart-open==1.9.0\n",
      "smmap==4.0.0\n",
      "sniffio==1.2.0\n",
      "snowballstemmer==2.1.0\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.2.1\n",
      "spacy==2.1.8\n",
      "sparse==0.13.0\n",
      "srsly==1.0.5\n",
      "sshtunnel==0.1.5\n",
      "statsmodels==0.10.2\n",
      "sympy==1.8\n",
      "tabulate==0.8.9\n",
      "tblib==1.7.0\n",
      "tenacity==8.0.1\n",
      "tensorboard==2.1.1\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.0\n",
      "tensorboardX==2.4\n",
      "tensorflow==2.1.0\n",
      "tensorflow-estimator==2.1.0\n",
      "tensorflow-gpu==2.1.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.12.1\n",
      "testpath==0.5.0\n",
      "textwrap3==0.9.2\n",
      "thinc==7.0.8\n",
      "threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "tifffile==2020.9.3\n",
      "tokenizers==0.10.3\n",
      "toml==0.10.2\n",
      "toolz==0.11.1\n",
      "torch==1.7.1\n",
      "torch-tb-profiler==0.2.1\n",
      "torchvision==0.8.2\n",
      "tornado==6.1\n",
      "tqdm==4.62.2\n",
      "traitlets==4.3.3\n",
      "transformers==4.5.1\n",
      "typed-ast==1.4.3\n",
      "typing-extensions==3.10.0.2\n",
      "ujson==4.1.0\n",
      "urllib3==1.25.11\n",
      "uuid==1.30\n",
      "vsts==0.1.25\n",
      "vsts-cd-manager==1.0.2\n",
      "waitress==2.0.0\n",
      "wasabi==0.8.2\n",
      "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1600965781394/work\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.2.1\n",
      "websockets==9.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wrapt==1.11.1\n",
      "xgboost==0.90\n",
      "xmltodict==0.12.0\n",
      "xxhash==2.0.2\n",
      "yapf==0.31.0\n",
      "yarl==1.6.3\n",
      "zict==2.0.0\n",
      "zipp==3.5.0\n",
      "zope.event==4.5.0\n",
      "zope.interface==5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "292px",
    "width": "228px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
